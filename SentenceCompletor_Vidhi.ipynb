{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'science': 20, 'sports': 20, 'business': 19, 'covid': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#MLFA Assignment 3\n",
    "#Sanskar Singh\n",
    "#19CH10047\n",
    "\n",
    "\n",
    "# Importing important libraries and reading in the training data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#LOADING IN DATA FOR PART 1\n",
    "\n",
    "#This will opan the file and save its data in our variables\n",
    "with open('traindata.csv', encoding=\"utf8\") as csv_file:\n",
    "    train_raw = csv.reader(csv_file, delimiter=',')\n",
    "    next(train_raw)\n",
    "    \n",
    "    train_dict = {}  #Dictionary containing text with category names as keys \n",
    "    categories = {}  #Dictionary containing the names of the categories and their no of occurences\n",
    "    \n",
    "    for line in train_raw:\n",
    "        if line[0] not in train_dict:\n",
    "            categories[line[0]] = 0\n",
    "            train_dict[line[0]]  = ''\n",
    "        train_dict[line[0]] += line[1]\n",
    "        \n",
    "        categories[line[0]] += 1\n",
    "    \n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for both parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03980099502487562\n",
      "This was a demonstration, refer code\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT FUNCTIONS WHICH WILL BE USED LATER\n",
    "\n",
    "\n",
    "\n",
    "# DEFINING PREPROCESSING FUNCTION FOR TEXTUAL DATA\n",
    "def text_processor(text):\n",
    "    #stop word in english\n",
    "    stop_words = stopwords.words('english')\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    #Split the words\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    #Strip the punctiations\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            new_word = word.translate(table)\n",
    "            new_word = ps.stem(new_word)\n",
    "            new_words.append(new_word)\n",
    "            \n",
    "    return new_words\n",
    "\n",
    "# Part [1(i)] Construct the vocabulary without stop-words (Stop words will not be included using above function first)\n",
    "# DEFINING FUNCTION TO GENERATE FREQUENCIES OF VALUES IN A LIST\n",
    "\n",
    "def vocabulary_generate(word_list):                 # We have already processed our text using the above function\n",
    "    vocabulary = {}                                 #This function takes in text and converts it into a dictionary\n",
    "    for word in word_list:                          # containing frequency of the words\n",
    "        if word  not in vocabulary:\n",
    "            vocabulary[word] = 0\n",
    "        vocabulary[word] += 1\n",
    "    return vocabulary\n",
    "\n",
    "#Part [1(ii)] Calculate the prior distribution of the labels \n",
    "# DEFINING FUNCTION TO GENERATE PROBABILITIES FROM FREQUENCIES\n",
    "\n",
    "def freq2probability(frequency_dict):               #In this function we convert a dictionary of frequencies\n",
    "    probabilities = {}                              #into a dictionary of probabilities, helpful in finding prior probs\n",
    "    freq_sum = 0\n",
    "    for frequency in frequency_dict.values():\n",
    "        freq_sum += frequency\n",
    "    for key,frequency in frequency_dict.items():\n",
    "        probabilities[key] = frequency/freq_sum\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "#Part[1(iii)]Calculate the class-conditional probabilities of each word in the vocabulary, for each topic \n",
    "def library_constructor(train_dict):\n",
    "    mega_lib = {}\n",
    "    for category,text in train_dict.items():                 #In this function we take in our training data and\n",
    "         text_words = text_processor(text)                   # calculate and store all the class conditional probabilities\n",
    "         freq_dict =  vocabulary_generate(text_words)\n",
    "         mega_lib[category] = freq2probability(freq_dict)\n",
    "    return mega_lib\n",
    "\n",
    "\n",
    "mega_lib = {}\n",
    "mega_lib = library_constructor(train_dict)\n",
    "\n",
    "print(mega_lib['science']['space'])                  # This value is only being printed to demonstrate\n",
    "print('This was a demonstration, refer code')        # how we have saved the class conditional probabilities\n",
    "                                                     # P(Xi=space| Y=science) is saved in the mega_lib as shown\n",
    "                                                     # The mega_lib thus contains all our class conditional probs in a similar manner\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# Part [1(iv)] For each test sentence, create the posterior distribution over the labels \n",
    "#NAIVE BAYES CLASSIFIER\n",
    "def naive_classifier(categories,mega_lib,test_sentence):          # This function takes in the mega_lib and outputs classification \n",
    "    test_words = text_processor(test_sentence)                    # uses naives bayes classification\n",
    "    confidence = {}\n",
    "    for category,category_priorprob in categories.items():\n",
    "        confidence[category] = category_priorprob\n",
    "        for test_word in test_words:\n",
    "            if test_word in mega_lib[category].keys():\n",
    "                confidence[category] *= mega_lib[category][test_word]\n",
    "            else:\n",
    "                confidence[category] *= 0.0005\n",
    "    K_inverse = 0\n",
    "    for con_value in confidence.values():\n",
    "          K_inverse += con_value\n",
    "    for category,con_value2 in confidence.items():\n",
    "         confidence[category]= con_value2/K_inverse\n",
    "    return confidence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING IN DATA FOR PART 1 FROM OUR TESTING SET\n",
    "\n",
    "test_lines_list = []\n",
    "test_lines_dict = {}\n",
    "\n",
    "with open('testdata.csv', encoding=\"utf8\") as csv_file2:\n",
    "    test_raw = csv.reader(csv_file2, delimiter=',')\n",
    "    next(test_raw)\n",
    "   #Dictionary containing text with category names as keys \n",
    "    \n",
    "    for line in test_raw:\n",
    "           test_lines_list.append(line[1])\n",
    "           test_lines_dict[line[1]]  = line[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Confidence in Science</th>\n",
       "      <th>Confidence in Sports</th>\n",
       "      <th>Confidence in Business</th>\n",
       "      <th>Confidence in Covid</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He estimates that 1,000-micrometer pellets cou...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.073310e-09</td>\n",
       "      <td>1.019644e-09</td>\n",
       "      <td>2.590748e-08</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“That’s enough time to potentially get to Mars...</td>\n",
       "      <td>8.021422e-01</td>\n",
       "      <td>8.172842e-05</td>\n",
       "      <td>1.960943e-01</td>\n",
       "      <td>1.681755e-03</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How exactly clumps of microbes might get expel...</td>\n",
       "      <td>9.998765e-01</td>\n",
       "      <td>3.541752e-07</td>\n",
       "      <td>1.203308e-04</td>\n",
       "      <td>2.849685e-06</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The microbes might get kicked up by small mete...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.806783e-11</td>\n",
       "      <td>1.089589e-09</td>\n",
       "      <td>1.897122e-11</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Someday, if microbial life is ever discovered ...</td>\n",
       "      <td>9.427356e-01</td>\n",
       "      <td>3.173955e-03</td>\n",
       "      <td>3.015257e-03</td>\n",
       "      <td>5.107514e-02</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In tennis, After the service has been correctl...</td>\n",
       "      <td>5.715968e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.114963e-14</td>\n",
       "      <td>3.577307e-19</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This may occur if a tennis player fails to hit...</td>\n",
       "      <td>3.012123e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.173428e-20</td>\n",
       "      <td>2.447843e-20</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>To win a game, a tennis player must win four p...</td>\n",
       "      <td>4.300483e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.303197e-13</td>\n",
       "      <td>1.738730e-13</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In tennis, It never has been satisfactorily ex...</td>\n",
       "      <td>3.615929e-04</td>\n",
       "      <td>9.996021e-01</td>\n",
       "      <td>1.726154e-05</td>\n",
       "      <td>1.907855e-05</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In tennis, The server’s score is called first;...</td>\n",
       "      <td>1.523936e-10</td>\n",
       "      <td>9.999685e-01</td>\n",
       "      <td>3.145206e-05</td>\n",
       "      <td>1.232286e-10</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Herb Kelleher makes it clear that his employee...</td>\n",
       "      <td>8.007789e-25</td>\n",
       "      <td>2.202805e-24</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.986698e-25</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>We don’t carry those sorts of customers. We wr...</td>\n",
       "      <td>2.654904e-03</td>\n",
       "      <td>8.893928e-05</td>\n",
       "      <td>9.971628e-01</td>\n",
       "      <td>9.338624e-05</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A Continental flight attendant once was offend...</td>\n",
       "      <td>3.011799e-02</td>\n",
       "      <td>3.011799e-02</td>\n",
       "      <td>9.081401e-01</td>\n",
       "      <td>3.162389e-02</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It was pretty offensive stuff, so the attendan...</td>\n",
       "      <td>5.221700e-05</td>\n",
       "      <td>5.221700e-05</td>\n",
       "      <td>9.994754e-01</td>\n",
       "      <td>4.201368e-04</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The fact is that some customers are just plain...</td>\n",
       "      <td>2.272261e-20</td>\n",
       "      <td>2.065431e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.385874e-20</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the virus appeared to be contained within Chin...</td>\n",
       "      <td>4.704061e-08</td>\n",
       "      <td>1.900391e-06</td>\n",
       "      <td>4.468858e-08</td>\n",
       "      <td>9.999980e-01</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>However, as of April 2020, over 210 countries ...</td>\n",
       "      <td>1.594258e-08</td>\n",
       "      <td>8.011149e-10</td>\n",
       "      <td>7.610591e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Similarly, SARS and MERS were also suspected t...</td>\n",
       "      <td>6.501585e-10</td>\n",
       "      <td>6.599261e-09</td>\n",
       "      <td>9.851043e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bats have been known to harbor coronaviruses f...</td>\n",
       "      <td>2.740616e-10</td>\n",
       "      <td>4.540318e-10</td>\n",
       "      <td>2.999910e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The identification of the original host helps ...</td>\n",
       "      <td>7.635331e-08</td>\n",
       "      <td>7.750039e-07</td>\n",
       "      <td>4.106948e-08</td>\n",
       "      <td>9.999991e-01</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  Confidence in Science  \\\n",
       "0   He estimates that 1,000-micrometer pellets cou...           1.000000e+00   \n",
       "1   “That’s enough time to potentially get to Mars...           8.021422e-01   \n",
       "2   How exactly clumps of microbes might get expel...           9.998765e-01   \n",
       "3   The microbes might get kicked up by small mete...           1.000000e+00   \n",
       "4   Someday, if microbial life is ever discovered ...           9.427356e-01   \n",
       "5   In tennis, After the service has been correctl...           5.715968e-18   \n",
       "6   This may occur if a tennis player fails to hit...           3.012123e-19   \n",
       "7   To win a game, a tennis player must win four p...           4.300483e-14   \n",
       "8   In tennis, It never has been satisfactorily ex...           3.615929e-04   \n",
       "9   In tennis, The server’s score is called first;...           1.523936e-10   \n",
       "10  Herb Kelleher makes it clear that his employee...           8.007789e-25   \n",
       "11  We don’t carry those sorts of customers. We wr...           2.654904e-03   \n",
       "12  A Continental flight attendant once was offend...           3.011799e-02   \n",
       "13  It was pretty offensive stuff, so the attendan...           5.221700e-05   \n",
       "14  The fact is that some customers are just plain...           2.272261e-20   \n",
       "15  the virus appeared to be contained within Chin...           4.704061e-08   \n",
       "16  However, as of April 2020, over 210 countries ...           1.594258e-08   \n",
       "17  Similarly, SARS and MERS were also suspected t...           6.501585e-10   \n",
       "18  Bats have been known to harbor coronaviruses f...           2.740616e-10   \n",
       "19  The identification of the original host helps ...           7.635331e-08   \n",
       "\n",
       "    Confidence in Sports  Confidence in Business  Confidence in Covid  \\\n",
       "0           1.073310e-09            1.019644e-09         2.590748e-08   \n",
       "1           8.172842e-05            1.960943e-01         1.681755e-03   \n",
       "2           3.541752e-07            1.203308e-04         2.849685e-06   \n",
       "3           1.806783e-11            1.089589e-09         1.897122e-11   \n",
       "4           3.173955e-03            3.015257e-03         5.107514e-02   \n",
       "5           1.000000e+00            2.114963e-14         3.577307e-19   \n",
       "6           1.000000e+00            9.173428e-20         2.447843e-20   \n",
       "7           1.000000e+00            1.303197e-13         1.738730e-13   \n",
       "8           9.996021e-01            1.726154e-05         1.907855e-05   \n",
       "9           9.999685e-01            3.145206e-05         1.232286e-10   \n",
       "10          2.202805e-24            1.000000e+00         4.986698e-25   \n",
       "11          8.893928e-05            9.971628e-01         9.338624e-05   \n",
       "12          3.011799e-02            9.081401e-01         3.162389e-02   \n",
       "13          5.221700e-05            9.994754e-01         4.201368e-04   \n",
       "14          2.065431e-17            1.000000e+00         2.385874e-20   \n",
       "15          1.900391e-06            4.468858e-08         9.999980e-01   \n",
       "16          8.011149e-10            7.610591e-10         1.000000e+00   \n",
       "17          6.599261e-09            9.851043e-10         1.000000e+00   \n",
       "18          4.540318e-10            2.999910e-09         1.000000e+00   \n",
       "19          7.750039e-07            4.106948e-08         9.999991e-01   \n",
       "\n",
       "   Prediction    Actual  \n",
       "0     science   science  \n",
       "1     science   science  \n",
       "2     science   science  \n",
       "3     science   science  \n",
       "4     science   science  \n",
       "5      sports    sports  \n",
       "6      sports    sports  \n",
       "7      sports    sports  \n",
       "8      sports    sports  \n",
       "9      sports    sports  \n",
       "10   business  business  \n",
       "11   business  business  \n",
       "12   business  business  \n",
       "13   business  business  \n",
       "14   business  business  \n",
       "15      covid     covid  \n",
       "16      covid     covid  \n",
       "17      covid     covid  \n",
       "18      covid     covid  \n",
       "19      covid     covid  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TABULATING OUR PREDICTIONS VS ACTUAL VALUES IN THE TRAINING DATA\n",
    "\n",
    "table_row =[]\n",
    "table_rows = []\n",
    "\n",
    "\n",
    "table_header = ['Sentence']\n",
    "for category in categories:\n",
    "    table_header.append('Confidence in '+ str(category).title())\n",
    "table_header.append('Prediction')\n",
    "table_header.append('Actual')\n",
    "\n",
    "for test_sentence in test_lines_list:\n",
    "    \n",
    "    table_row =[]\n",
    "    \n",
    "    table_row.append(test_sentence)\n",
    "    confidences = naive_classifier(categories, mega_lib,test_sentence)\n",
    "    for category in categories:\n",
    "        table_row.append(confidences[category])\n",
    "    table_row.append(max(confidences, key =confidences.get))\n",
    "    table_row.append(test_lines_dict[test_sentence]) \n",
    "    table_rows.append(table_row)\n",
    "    \n",
    "data_frame = pd.DataFrame(table_rows,columns = table_header)\n",
    "data_frame\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model determined from the testing data is \n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy of our predictions\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for sentence in test_lines_list:\n",
    "    prediction_dict = naive_classifier(categories, mega_lib, sentence)\n",
    "    prediction = max(prediction_dict, key = prediction_dict.get)\n",
    "    if prediction == test_lines_dict[sentence]:\n",
    "        correct += 1\n",
    "        \n",
    "accuracy = 100*(correct/len(test_lines_list))\n",
    "\n",
    "print(\"The accuracy of our model determined from the testing data is \\n\" + str(accuracy) +'%' )\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING IN DATA FOR PART 2\n",
    "\n",
    "train_lines = []\n",
    "with open('40.csv', encoding=\"utf8\") as csv_file3:\n",
    "    train_raw2 = csv.reader(csv_file3, delimiter=',')\n",
    "    next(train_raw2)\n",
    "    train_text = ''\n",
    "    for line in train_raw2:\n",
    "        train_text += str(line)\n",
    "        \n",
    "        train_lines.append(line[0])\n",
    "train_text  = text_processor(train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating prior probabilitiies\n",
    "\n",
    "\n",
    "vocabulary40_all = vocabulary_generate(train_text)\n",
    "word_prior_probs = freq2probability(vocabulary40_all)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING CLASS CONDITIONAL PROBABILITIES\n",
    "\n",
    "word_lib = {}                                            #Here we loop through every single word to generate a dictionary                               \n",
    "                                                         # corresponding to every word containing the class conditional \n",
    "for word in train_text:                                  # probabilites(finally as uber_lib) of all other words\n",
    "    for i in range(len(train_lines)):\n",
    "        if word not in word_lib:\n",
    "            word_lib[word] = ''\n",
    "        if word in (text_processor(train_lines[i])):\n",
    "            word_lib[word] += train_lines[i]\n",
    "\n",
    "uber_lib = library_constructor(word_lib)   #Here uber_lib serves a similar function to mega_lib earlier\n",
    "                                           #It contains the class conditional probabilites of every word given another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING IN THE TESTING SET\n",
    "\n",
    "test_lines = []\n",
    "with open('10.csv', encoding=\"utf8\") as csv_file4:\n",
    "    test_raw2 = csv.reader(csv_file4, delimiter=',')\n",
    "    next(test_raw2)\n",
    "    for line in test_raw2:\n",
    "        test_lines.append(line[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eating healthy food is important for maintainn...</td>\n",
       "      <td>midst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Following a healthy diet will boost your _____</td>\n",
       "      <td>healthi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avoid eating chemical additives, added sugars ...</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your diet should be rich of vitamins D,K, calc...</td>\n",
       "      <td>calcium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The healthier the food you eat, the better you...</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dehydration causes tiredness, low energy and h...</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>People with kidney disease should avoid eating...</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We should avoid eating transfats. Eating healt...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mindless eating is often caused by eating alon...</td>\n",
       "      <td>front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eating more junk food will make you feel uncom...</td>\n",
       "      <td>junk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Prediction\n",
       "0  Eating healthy food is important for maintainn...      midst\n",
       "1     Following a healthy diet will boost your _____    healthi\n",
       "2  Avoid eating chemical additives, added sugars ...         ad\n",
       "3  Your diet should be rich of vitamins D,K, calc...    calcium\n",
       "4  The healthier the food you eat, the better you...     better\n",
       "5  Dehydration causes tiredness, low energy and h...      water\n",
       "6  People with kidney disease should avoid eating...       much\n",
       "7  We should avoid eating transfats. Eating healt...       food\n",
       "8  Mindless eating is often caused by eating alon...      front\n",
       "9  Eating more junk food will make you feel uncom...       junk"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TABULATING OUR PREDICTIONS OVER THE TESTING SET\n",
    "\n",
    "table_row2 =[]\n",
    "table_rows2 = []\n",
    "\n",
    "\n",
    "table_header2 = ['Sentence']\n",
    "table_header2.append('Prediction')\n",
    "\n",
    "for test_sentence in test_lines:\n",
    "    \n",
    "    table_row2 =[]\n",
    "    \n",
    "    table_row2.append(test_sentence)\n",
    "    confidences2 = naive_classifier(vocabulary40_all, uber_lib,test_sentence)\n",
    "    table_row2.append(max(confidences2, key =confidences2.get))\n",
    "    table_rows2.append(table_row2)\n",
    "    \n",
    "data_frame2 = pd.DataFrame(table_rows2, columns = table_header2)\n",
    "data_frame2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
